{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PROJECT B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re \n",
    "import nltk\n",
    "import random\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import recall_score   \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the dataset\n",
    "blog_df = pd.read_csv(\"Dataset - blogtext.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>topic</th>\n",
       "      <th>sign</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2059027</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>14,May,2004</td>\n",
       "      <td>Info has been found (+/- 100 pages,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2059027</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>13,May,2004</td>\n",
       "      <td>These are the team members:   Drewe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2059027</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>12,May,2004</td>\n",
       "      <td>In het kader van kernfusie op aarde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2059027</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>12,May,2004</td>\n",
       "      <td>testing!!!  testing!!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3581210</td>\n",
       "      <td>male</td>\n",
       "      <td>33</td>\n",
       "      <td>InvestmentBanking</td>\n",
       "      <td>Aquarius</td>\n",
       "      <td>11,June,2004</td>\n",
       "      <td>Thanks to Yahoo!'s Toolbar I can ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id gender  age              topic      sign          date  \\\n",
       "0  2059027   male   15            Student       Leo   14,May,2004   \n",
       "1  2059027   male   15            Student       Leo   13,May,2004   \n",
       "2  2059027   male   15            Student       Leo   12,May,2004   \n",
       "3  2059027   male   15            Student       Leo   12,May,2004   \n",
       "4  3581210   male   33  InvestmentBanking  Aquarius  11,June,2004   \n",
       "\n",
       "                                                text  \n",
       "0             Info has been found (+/- 100 pages,...  \n",
       "1             These are the team members:   Drewe...  \n",
       "2             In het kader van kernfusie op aarde...  \n",
       "3                   testing!!!  testing!!!            \n",
       "4               Thanks to Yahoo!'s Toolbar I can ...  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking sample data to see the overview of the dataset\n",
    "blog_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 681284 entries, 0 to 681283\n",
      "Data columns (total 7 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   id      681284 non-null  int64 \n",
      " 1   gender  681284 non-null  object\n",
      " 2   age     681284 non-null  int64 \n",
      " 3   topic   681284 non-null  object\n",
      " 4   sign    681284 non-null  object\n",
      " 5   date    681284 non-null  object\n",
      " 6   text    681284 non-null  object\n",
      "dtypes: int64(2), object(5)\n",
      "memory usage: 36.4+ MB\n"
     ]
    }
   ],
   "source": [
    "# checking the info of the dataset\n",
    "blog_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id        0\n",
       "gender    0\n",
       "age       0\n",
       "topic     0\n",
       "sign      0\n",
       "date      0\n",
       "text      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking for any null values\n",
    "blog_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(681284, 7)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking the shape of the dataset\n",
    "blog_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# taking the subset of the dataset\n",
    "blog_df_subset = blog_df.head(20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "blog_df_subset.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>topic</th>\n",
       "      <th>sign</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2059027</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>14,May,2004</td>\n",
       "      <td>Info has been found (+/- 100 pages,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2059027</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>13,May,2004</td>\n",
       "      <td>These are the team members:   Drewe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2059027</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>12,May,2004</td>\n",
       "      <td>In het kader van kernfusie op aarde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2059027</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>12,May,2004</td>\n",
       "      <td>testing!!!  testing!!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3581210</td>\n",
       "      <td>male</td>\n",
       "      <td>33</td>\n",
       "      <td>InvestmentBanking</td>\n",
       "      <td>Aquarius</td>\n",
       "      <td>11,June,2004</td>\n",
       "      <td>Thanks to Yahoo!'s Toolbar I can ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id gender  age              topic      sign          date  \\\n",
       "0  2059027   male   15            Student       Leo   14,May,2004   \n",
       "1  2059027   male   15            Student       Leo   13,May,2004   \n",
       "2  2059027   male   15            Student       Leo   12,May,2004   \n",
       "3  2059027   male   15            Student       Leo   12,May,2004   \n",
       "4  3581210   male   33  InvestmentBanking  Aquarius  11,June,2004   \n",
       "\n",
       "                                                text  \n",
       "0             Info has been found (+/- 100 pages,...  \n",
       "1             These are the team members:   Drewe...  \n",
       "2             In het kader van kernfusie op aarde...  \n",
       "3                   testing!!!  testing!!!            \n",
       "4               Thanks to Yahoo!'s Toolbar I can ...  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blog_df_subset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 7)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blog_df_subset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing the text column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                   Info has been found (+/- 100 pages,...\n",
       "1                   These are the team members:   Drewe...\n",
       "2                   In het kader van kernfusie op aarde...\n",
       "3                         testing!!!  testing!!!          \n",
       "4                     Thanks to Yahoo!'s Toolbar I can ...\n",
       "                               ...                        \n",
       "19995                     Writing tests are retarded......\n",
       "19996                     Ok nothing happened that was ...\n",
       "19997                     So Daniel who do you want to ...\n",
       "19998                     I finally got around to seein...\n",
       "19999                     My chemistry teacher must thi...\n",
       "Name: text, Length: 20000, dtype: object"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# text column\n",
    "blog_df_subset['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\aruns\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stopwords=set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to process the text\n",
    "def Text_Processing(text):\n",
    "    # removing the unwanted characters\n",
    "    process_text = re.sub(r'[^A-Za-z]+',' ',text)\n",
    "    \n",
    "    # converting into lower text\n",
    "    process_text = process_text.lower()\n",
    "    \n",
    "    # removing the trailing and leading spaces\n",
    "    process_text = process_text.strip()\n",
    "    \n",
    "    #removing stop words\n",
    "    process_text = ' '.join([words for words in process_text.split() if words not in stopwords])\n",
    "    \n",
    "    # return processed text\n",
    "    return process_text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying the text processing to the text column\n",
    "blog_df_subset['processed_text'] = blog_df_subset['text'].apply(Text_Processing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ah korean language looks difficult first figure read hanguel korea surprisingly easy learn alphabet characters seems easy vocabulary starts oh backwards us sentence structure yikes luckily many options us slow witted foreigners take language course could list urllink joongang article says lot resources urllink well guy motivation jeon ji hyun latest something actually star movies cfs hear means commercial feature positive saw latest movie sunday night hard describe name english version windstruck korean version yeochinso short ne yeojachingu rul sogayhamnida like introduce girlfriend surprisingly titles make sense like website korean english looks quite good actually urllink movie shown theatres subtitles special times info urllink list many theatres seoul click urllink urllink great reason learn korean already married went foreigners well local korean national course korean take picture put urllink movie hof bar update bud mine passed urllink link giordano ad apparently aired korea nothing xxx sensibilities sort'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Processed data example\n",
    "blog_df_subset['processed_text'][10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"             Ah, the Korean language...it looks so difficult at first, then as you figure out how to read Hanguel (Korea's surprisingly easy-to-learn alphabet of 24 characters) it seems so easy. Then the vocabulary starts. Oh no. Then the backwards (to us) sentence structure.  Yikes!  Luckily there are many options for us slow-witted foreigners to take on the language.  Of course I could list them here but  urlLink this JoongAng article  says a lot and there are more resources  urlLink here .    Well, if you're a guy here is some motivation for you: Jeon Ji Hyun (전지현), the latest 20-something (24, actually) star of movies and CFs (I hear this means Commercial Feature, but not positive).  I saw her latest movie on Sunday night.  It's hard to describe the name...the English version is 'Windstruck' but the Korean version is 여친소 (yeochinso) which is short for 내여자친구를소개합니다 (ne yeojachingu rul sogayhamnida) or 'I'd like to introduce you to my girlfriend'.  Surprisingly, both titles make sense.  If you like, there is a website (Korean and English, looks quite good, actually)  urlLink here .  The movie is shown in theatres with subtitles at special times, that info is  urlLink here . For a list of many of the theatres in Seoul click....  urlLink here!    urlLink    Here is a great reason to learn Korean...if I wasn't already married, that is.  I went with a few foreigners as well as a local/Korean/National...of course the Korean HAD to take a picture...so I HAVE to put it up here.   urlLink    Here we are after the movie...and before the hof/bar.     Update:  A bud of mine passed  urlLink this link  on to me. It's 전지현 in a Giordano ad. Apparently it was NOT aired in Korea (nothing XXX about it, it's all about sensibilities of some sort).         \""
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Original data example\n",
    "blog_df_subset['text'][10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "blog_df_subset['text'] = blog_df_subset['processed_text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge columns for multi-label classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# age column converting to object type\n",
    "blog_df_subset['age']=blog_df_subset['age'].astype('object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merging the label columns\n",
    "blog_df_subset['labels']=blog_df_subset.apply(lambda col: [col['gender'],str(col['age']),col['topic'],col['sign']], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>topic</th>\n",
       "      <th>sign</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>processed_text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2059027</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>14,May,2004</td>\n",
       "      <td>info found pages mb pdf files wait untill team...</td>\n",
       "      <td>info found pages mb pdf files wait untill team...</td>\n",
       "      <td>[male, 15, Student, Leo]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2059027</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>13,May,2004</td>\n",
       "      <td>team members drewes van der laag urllink mail ...</td>\n",
       "      <td>team members drewes van der laag urllink mail ...</td>\n",
       "      <td>[male, 15, Student, Leo]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2059027</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>12,May,2004</td>\n",
       "      <td>het kader van kernfusie op aarde maak je eigen...</td>\n",
       "      <td>het kader van kernfusie op aarde maak je eigen...</td>\n",
       "      <td>[male, 15, Student, Leo]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2059027</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>12,May,2004</td>\n",
       "      <td>testing testing</td>\n",
       "      <td>testing testing</td>\n",
       "      <td>[male, 15, Student, Leo]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3581210</td>\n",
       "      <td>male</td>\n",
       "      <td>33</td>\n",
       "      <td>InvestmentBanking</td>\n",
       "      <td>Aquarius</td>\n",
       "      <td>11,June,2004</td>\n",
       "      <td>thanks yahoo toolbar capture urls popups means...</td>\n",
       "      <td>thanks yahoo toolbar capture urls popups means...</td>\n",
       "      <td>[male, 33, InvestmentBanking, Aquarius]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>1019710</td>\n",
       "      <td>male</td>\n",
       "      <td>16</td>\n",
       "      <td>Student</td>\n",
       "      <td>Pisces</td>\n",
       "      <td>10,February,2004</td>\n",
       "      <td>writing tests retarded along chemistry project...</td>\n",
       "      <td>writing tests retarded along chemistry project...</td>\n",
       "      <td>[male, 16, Student, Pisces]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>1019710</td>\n",
       "      <td>male</td>\n",
       "      <td>16</td>\n",
       "      <td>Student</td>\n",
       "      <td>Pisces</td>\n",
       "      <td>31,March,2004</td>\n",
       "      <td>ok nothing happened crazy except chipped back ...</td>\n",
       "      <td>ok nothing happened crazy except chipped back ...</td>\n",
       "      <td>[male, 16, Student, Pisces]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>1019710</td>\n",
       "      <td>male</td>\n",
       "      <td>16</td>\n",
       "      <td>Student</td>\n",
       "      <td>Pisces</td>\n",
       "      <td>30,March,2004</td>\n",
       "      <td>daniel want win election get question alot ok ...</td>\n",
       "      <td>daniel want win election get question alot ok ...</td>\n",
       "      <td>[male, 16, Student, Pisces]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>1019710</td>\n",
       "      <td>male</td>\n",
       "      <td>16</td>\n",
       "      <td>Student</td>\n",
       "      <td>Pisces</td>\n",
       "      <td>29,March,2004</td>\n",
       "      <td>finally got around seeing passion christ well ...</td>\n",
       "      <td>finally got around seeing passion christ well ...</td>\n",
       "      <td>[male, 16, Student, Pisces]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>1019710</td>\n",
       "      <td>male</td>\n",
       "      <td>16</td>\n",
       "      <td>Student</td>\n",
       "      <td>Pisces</td>\n",
       "      <td>28,March,2004</td>\n",
       "      <td>chemistry teacher must think funny make stress...</td>\n",
       "      <td>chemistry teacher must think funny make stress...</td>\n",
       "      <td>[male, 16, Student, Pisces]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id gender age              topic      sign              date  \\\n",
       "0      2059027   male  15            Student       Leo       14,May,2004   \n",
       "1      2059027   male  15            Student       Leo       13,May,2004   \n",
       "2      2059027   male  15            Student       Leo       12,May,2004   \n",
       "3      2059027   male  15            Student       Leo       12,May,2004   \n",
       "4      3581210   male  33  InvestmentBanking  Aquarius      11,June,2004   \n",
       "...        ...    ...  ..                ...       ...               ...   \n",
       "19995  1019710   male  16            Student    Pisces  10,February,2004   \n",
       "19996  1019710   male  16            Student    Pisces     31,March,2004   \n",
       "19997  1019710   male  16            Student    Pisces     30,March,2004   \n",
       "19998  1019710   male  16            Student    Pisces     29,March,2004   \n",
       "19999  1019710   male  16            Student    Pisces     28,March,2004   \n",
       "\n",
       "                                                    text  \\\n",
       "0      info found pages mb pdf files wait untill team...   \n",
       "1      team members drewes van der laag urllink mail ...   \n",
       "2      het kader van kernfusie op aarde maak je eigen...   \n",
       "3                                        testing testing   \n",
       "4      thanks yahoo toolbar capture urls popups means...   \n",
       "...                                                  ...   \n",
       "19995  writing tests retarded along chemistry project...   \n",
       "19996  ok nothing happened crazy except chipped back ...   \n",
       "19997  daniel want win election get question alot ok ...   \n",
       "19998  finally got around seeing passion christ well ...   \n",
       "19999  chemistry teacher must think funny make stress...   \n",
       "\n",
       "                                          processed_text  \\\n",
       "0      info found pages mb pdf files wait untill team...   \n",
       "1      team members drewes van der laag urllink mail ...   \n",
       "2      het kader van kernfusie op aarde maak je eigen...   \n",
       "3                                        testing testing   \n",
       "4      thanks yahoo toolbar capture urls popups means...   \n",
       "...                                                  ...   \n",
       "19995  writing tests retarded along chemistry project...   \n",
       "19996  ok nothing happened crazy except chipped back ...   \n",
       "19997  daniel want win election get question alot ok ...   \n",
       "19998  finally got around seeing passion christ well ...   \n",
       "19999  chemistry teacher must think funny make stress...   \n",
       "\n",
       "                                        labels  \n",
       "0                     [male, 15, Student, Leo]  \n",
       "1                     [male, 15, Student, Leo]  \n",
       "2                     [male, 15, Student, Leo]  \n",
       "3                     [male, 15, Student, Leo]  \n",
       "4      [male, 33, InvestmentBanking, Aquarius]  \n",
       "...                                        ...  \n",
       "19995              [male, 16, Student, Pisces]  \n",
       "19996              [male, 16, Student, Pisces]  \n",
       "19997              [male, 16, Student, Pisces]  \n",
       "19998              [male, 16, Student, Pisces]  \n",
       "19999              [male, 16, Student, Pisces]  \n",
       "\n",
       "[20000 rows x 9 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blog_df_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing the columns id, gender, age, topic, sign, date, text\n",
    "blog_df_subset = blog_df_subset.drop(['id','gender','age','topic','sign','date', 'text'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>processed_text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>info found pages mb pdf files wait untill team...</td>\n",
       "      <td>[male, 15, Student, Leo]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>team members drewes van der laag urllink mail ...</td>\n",
       "      <td>[male, 15, Student, Leo]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>het kader van kernfusie op aarde maak je eigen...</td>\n",
       "      <td>[male, 15, Student, Leo]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>testing testing</td>\n",
       "      <td>[male, 15, Student, Leo]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>thanks yahoo toolbar capture urls popups means...</td>\n",
       "      <td>[male, 33, InvestmentBanking, Aquarius]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>writing tests retarded along chemistry project...</td>\n",
       "      <td>[male, 16, Student, Pisces]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>ok nothing happened crazy except chipped back ...</td>\n",
       "      <td>[male, 16, Student, Pisces]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>daniel want win election get question alot ok ...</td>\n",
       "      <td>[male, 16, Student, Pisces]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>finally got around seeing passion christ well ...</td>\n",
       "      <td>[male, 16, Student, Pisces]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>chemistry teacher must think funny make stress...</td>\n",
       "      <td>[male, 16, Student, Pisces]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          processed_text  \\\n",
       "0      info found pages mb pdf files wait untill team...   \n",
       "1      team members drewes van der laag urllink mail ...   \n",
       "2      het kader van kernfusie op aarde maak je eigen...   \n",
       "3                                        testing testing   \n",
       "4      thanks yahoo toolbar capture urls popups means...   \n",
       "...                                                  ...   \n",
       "19995  writing tests retarded along chemistry project...   \n",
       "19996  ok nothing happened crazy except chipped back ...   \n",
       "19997  daniel want win election get question alot ok ...   \n",
       "19998  finally got around seeing passion christ well ...   \n",
       "19999  chemistry teacher must think funny make stress...   \n",
       "\n",
       "                                        labels  \n",
       "0                     [male, 15, Student, Leo]  \n",
       "1                     [male, 15, Student, Leo]  \n",
       "2                     [male, 15, Student, Leo]  \n",
       "3                     [male, 15, Student, Leo]  \n",
       "4      [male, 33, InvestmentBanking, Aquarius]  \n",
       "...                                        ...  \n",
       "19995              [male, 16, Student, Pisces]  \n",
       "19996              [male, 16, Student, Pisces]  \n",
       "19997              [male, 16, Student, Pisces]  \n",
       "19998              [male, 16, Student, Pisces]  \n",
       "19999              [male, 16, Student, Pisces]  \n",
       "\n",
       "[20000 rows x 2 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blog_df_subset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Separating features & labels and split into training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = blog_df_subset['processed_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = blog_df_subset['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain,Xtest,Ytrain,Ytest=train_test_split(X,y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xtrain shape (16000,)\n",
      "Xtest shape (4000,)\n",
      "Ytrain shape (16000,)\n",
      "Ytest shape (4000,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Xtrain shape\", Xtrain.shape)\n",
    "print(\"Xtest shape\", Xtest.shape)\n",
    "print(\"Ytrain shape\", Ytrain.shape)\n",
    "print(\"Ytest shape\", Ytest.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorizing features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializing the vectorization\n",
    "vectorizer=CountVectorizer(binary=True, ngram_range=(1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorizing features\n",
    "X=vectorizer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aa',\n",
       " 'aa aa',\n",
       " 'aa advert',\n",
       " 'aa amazing',\n",
       " 'aa anger',\n",
       " 'aa batteries',\n",
       " 'aa compared',\n",
       " 'aa ended',\n",
       " 'aa htm',\n",
       " 'aa keeps',\n",
       " 'aa months',\n",
       " 'aa nice',\n",
       " 'aa process',\n",
       " 'aa real',\n",
       " 'aa sd',\n",
       " 'aa species',\n",
       " 'aa sudden',\n",
       " 'aa ting',\n",
       " 'aaa',\n",
       " 'aaa aaa',\n",
       " 'aaa andy',\n",
       " 'aaa assistance',\n",
       " 'aaa come',\n",
       " 'aaa discount',\n",
       " 'aaa get',\n",
       " 'aaa hahahaha',\n",
       " 'aaa joe',\n",
       " 'aaa looks',\n",
       " 'aaa rated',\n",
       " 'aaa someone',\n",
       " 'aaa take',\n",
       " 'aaa tow',\n",
       " 'aaa travel',\n",
       " 'aaaa',\n",
       " 'aaaa jet',\n",
       " 'aaaaaa',\n",
       " 'aaaaaa comes',\n",
       " 'aaaaaa honest',\n",
       " 'aaaaaaa',\n",
       " 'aaaaaaa love',\n",
       " 'aaaaaaaaaaaah',\n",
       " 'aaaaaaaaaaah',\n",
       " 'aaaaaaaaaaah drove',\n",
       " 'aaaaaaaaaaahhhhhhhhhhhhhhhhhhh',\n",
       " 'aaaaaaaaaaahhhhhhhhhhhhhhhhhhh hw',\n",
       " 'aaaaaaaaaaand',\n",
       " 'aaaaaaaaaaand done',\n",
       " 'aaaaaaaaaaauuugh',\n",
       " 'aaaaaaaaaaauuugh least',\n",
       " 'aaaaaaaaaaawwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwww']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking few samples\n",
    "vectorizer.get_feature_names()[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>aa aa</th>\n",
       "      <th>aa advert</th>\n",
       "      <th>aa amazing</th>\n",
       "      <th>aa anger</th>\n",
       "      <th>aa batteries</th>\n",
       "      <th>aa compared</th>\n",
       "      <th>aa ended</th>\n",
       "      <th>aa htm</th>\n",
       "      <th>aa keeps</th>\n",
       "      <th>...</th>\n",
       "      <th>aaahhhh diva</th>\n",
       "      <th>aaahhhh excited</th>\n",
       "      <th>aaahing</th>\n",
       "      <th>aaahing much</th>\n",
       "      <th>aaanyway</th>\n",
       "      <th>aaanyway found</th>\n",
       "      <th>aaanyway shut</th>\n",
       "      <th>aaargh</th>\n",
       "      <th>aaargh damn</th>\n",
       "      <th>aaargh decided</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 150 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    aa  aa aa  aa advert  aa amazing  aa anger  aa batteries  aa compared  \\\n",
       "0    0      0          0           0         0             0            0   \n",
       "1    0      0          0           0         0             0            0   \n",
       "2    0      0          0           0         0             0            0   \n",
       "3    0      0          0           0         0             0            0   \n",
       "4    0      0          0           0         0             0            0   \n",
       "..  ..    ...        ...         ...       ...           ...          ...   \n",
       "95   0      0          0           0         0             0            0   \n",
       "96   0      0          0           0         0             0            0   \n",
       "97   0      0          0           0         0             0            0   \n",
       "98   0      0          0           0         0             0            0   \n",
       "99   0      0          0           0         0             0            0   \n",
       "\n",
       "    aa ended  aa htm  aa keeps  ...  aaahhhh diva  aaahhhh excited  aaahing  \\\n",
       "0          0       0         0  ...             0                0        0   \n",
       "1          0       0         0  ...             0                0        0   \n",
       "2          0       0         0  ...             0                0        0   \n",
       "3          0       0         0  ...             0                0        0   \n",
       "4          0       0         0  ...             0                0        0   \n",
       "..       ...     ...       ...  ...           ...              ...      ...   \n",
       "95         0       0         0  ...             0                0        0   \n",
       "96         0       0         0  ...             0                0        0   \n",
       "97         0       0         0  ...             0                0        0   \n",
       "98         0       0         0  ...             0                0        0   \n",
       "99         0       0         0  ...             0                0        0   \n",
       "\n",
       "    aaahing much  aaanyway  aaanyway found  aaanyway shut  aaargh  \\\n",
       "0              0         0               0              0       0   \n",
       "1              0         0               0              0       0   \n",
       "2              0         0               0              0       0   \n",
       "3              0         0               0              0       0   \n",
       "4              0         0               0              0       0   \n",
       "..           ...       ...             ...            ...     ...   \n",
       "95             0         0               0              0       0   \n",
       "96             0         0               0              0       0   \n",
       "97             0         0               0              0       0   \n",
       "98             0         0               0              0       0   \n",
       "99             0         0               0              0       0   \n",
       "\n",
       "    aaargh damn  aaargh decided  \n",
       "0             0               0  \n",
       "1             0               0  \n",
       "2             0               0  \n",
       "3             0               0  \n",
       "4             0               0  \n",
       "..          ...             ...  \n",
       "95            0               0  \n",
       "96            0               0  \n",
       "97            0               0  \n",
       "98            0               0  \n",
       "99            0               0  \n",
       "\n",
       "[100 rows x 150 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# printing the document term matrix for few samples\n",
    "df = pd.DataFrame(X[:100,:150].toarray(), columns=vectorizer.get_feature_names()[:150])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize training and testing features\n",
    "Xtrain_vec = vectorizer.transform(Xtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtest_vec = vectorizer.transform(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 639842)\t1\n",
      "  (0, 640989)\t1\n",
      "  (0, 759527)\t1\n",
      "  (0, 762526)\t1\n",
      "  (0, 1138396)\t1\n",
      "  (0, 1138558)\t1\n",
      "  (0, 1213285)\t1\n",
      "  (0, 1217425)\t1\n"
     ]
    }
   ],
   "source": [
    "print(Xtrain_vec[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 8815)\t1\n",
      "  (0, 9208)\t1\n",
      "  (0, 10282)\t1\n",
      "  (0, 10388)\t1\n",
      "  (0, 12179)\t1\n",
      "  (0, 12180)\t1\n",
      "  (0, 45643)\t1\n",
      "  (0, 45644)\t1\n",
      "  (0, 55093)\t1\n",
      "  (0, 55116)\t1\n",
      "  (0, 55276)\t1\n",
      "  (0, 55317)\t1\n",
      "  (0, 55506)\t1\n",
      "  (0, 56854)\t1\n",
      "  (0, 56860)\t1\n",
      "  (0, 60509)\t1\n",
      "  (0, 60557)\t1\n",
      "  (0, 62930)\t1\n",
      "  (0, 63171)\t1\n",
      "  (0, 64586)\t1\n",
      "  (0, 64593)\t1\n",
      "  (0, 66026)\t1\n",
      "  (0, 66040)\t1\n",
      "  (0, 67829)\t1\n",
      "  (0, 67940)\t1\n",
      "  :\t:\n",
      "  (0, 1235945)\t1\n",
      "  (0, 1236045)\t1\n",
      "  (0, 1236254)\t1\n",
      "  (0, 1236267)\t1\n",
      "  (0, 1247112)\t1\n",
      "  (0, 1247161)\t1\n",
      "  (0, 1254528)\t1\n",
      "  (0, 1254760)\t1\n",
      "  (0, 1256810)\t1\n",
      "  (0, 1257518)\t1\n",
      "  (0, 1258102)\t1\n",
      "  (0, 1258539)\t1\n",
      "  (0, 1258726)\t1\n",
      "  (0, 1263851)\t1\n",
      "  (0, 1264169)\t1\n",
      "  (0, 1265436)\t1\n",
      "  (0, 1265559)\t1\n",
      "  (0, 1269944)\t1\n",
      "  (0, 1269981)\t1\n",
      "  (0, 1271567)\t1\n",
      "  (0, 1271569)\t1\n",
      "  (0, 1283558)\t1\n",
      "  (0, 1283701)\t1\n",
      "  (0, 1289827)\t1\n",
      "  (0, 1289848)\t1\n"
     ]
    }
   ],
   "source": [
    "print(Xtest_vec[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dictionary to get the count of every label "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the label counts\n",
    "label_counts=dict()\n",
    "\n",
    "for labels in blog_df_subset.labels.values:\n",
    "    for label in labels:\n",
    "        if label in label_counts:\n",
    "            label_counts[label]+=1\n",
    "        else:\n",
    "            label_counts[label]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'male': 11354,\n",
       " '15': 1097,\n",
       " 'Student': 2637,\n",
       " 'Leo': 1732,\n",
       " '33': 769,\n",
       " 'InvestmentBanking': 71,\n",
       " 'Aquarius': 1313,\n",
       " 'female': 8646,\n",
       " '14': 811,\n",
       " 'indUnk': 7789,\n",
       " 'Aries': 5209,\n",
       " '25': 1190,\n",
       " 'Capricorn': 930,\n",
       " '17': 1961,\n",
       " 'Gemini': 780,\n",
       " '23': 1963,\n",
       " 'Non-Profit': 204,\n",
       " 'Cancer': 1536,\n",
       " 'Banking': 89,\n",
       " '37': 130,\n",
       " 'Sagittarius': 2153,\n",
       " '26': 919,\n",
       " '24': 1557,\n",
       " 'Scorpio': 1485,\n",
       " '27': 2320,\n",
       " 'Education': 759,\n",
       " '45': 72,\n",
       " 'Engineering': 357,\n",
       " 'Libra': 983,\n",
       " 'Science': 87,\n",
       " '34': 871,\n",
       " '41': 82,\n",
       " 'Communications-Media': 414,\n",
       " 'BusinessServices': 184,\n",
       " 'Sports-Recreation': 120,\n",
       " 'Virgo': 871,\n",
       " 'Taurus': 1330,\n",
       " 'Arts': 358,\n",
       " 'Pisces': 1678,\n",
       " '44': 9,\n",
       " '16': 1236,\n",
       " 'Internet': 778,\n",
       " 'Museums-Libraries': 67,\n",
       " 'Accounting': 35,\n",
       " '39': 105,\n",
       " '35': 2494,\n",
       " 'Technology': 2989,\n",
       " '36': 1726,\n",
       " 'Law': 47,\n",
       " '46': 188,\n",
       " 'Consulting': 166,\n",
       " 'Automotive': 111,\n",
       " '42': 47,\n",
       " 'Religion': 182,\n",
       " '13': 113,\n",
       " 'Fashion': 1622,\n",
       " '38': 85,\n",
       " '43': 6,\n",
       " 'Publishing': 70,\n",
       " '40': 1,\n",
       " 'Marketing': 207,\n",
       " 'LawEnforcement-Security': 90,\n",
       " 'HumanResources': 15,\n",
       " 'Telecommunications': 10,\n",
       " 'Military': 19,\n",
       " 'Government': 187,\n",
       " 'Transportation': 46,\n",
       " 'Architecture': 45,\n",
       " 'Advertising': 42,\n",
       " '47': 8,\n",
       " 'Agriculture': 46,\n",
       " 'Biotech': 36,\n",
       " 'RealEstate': 7,\n",
       " 'Manufacturing': 93,\n",
       " '48': 240,\n",
       " 'Construction': 21}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializing the multilabel binarizer\n",
    "binarizer=MultiLabelBinarizer(classes=sorted(label_counts.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transforming training labels\n",
    "Ytrain=binarizer.fit_transform(Ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transforming testing labels\n",
    "Ytest = binarizer.fit_transform(Ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(solver = 'lbfgs', max_iter=500)\n",
    "\n",
    "#One-vs-Rest approach\n",
    "clf = OneVsRestClassifier(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneVsRestClassifier(estimator=LogisticRegression(max_iter=500))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(Xtrain_vec, Ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=clf.predict(Xtest_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy score:  0.93475\n",
      "Testing Accuracy score:  0.162\n",
      "f1 score:  0.5300136708231492\n"
     ]
    }
   ],
   "source": [
    "clf_Train = clf.score(Xtrain_vec, Ytrain)\n",
    "print(\"Training Accuracy score: \", clf_Train)\n",
    "\n",
    "clf_Test = clf.score(Xtest_vec,Ytest)\n",
    "print(\"Testing Accuracy score: \", clf_Test)\n",
    "\n",
    "pred = clf.predict(Xtest_vec)\n",
    "\n",
    "clf_f1 = f1_score(Ytest, pred,average='micro')\n",
    "print(\"f1 score: \",clf_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scores_averaging(Ytest, pred, avg_metric):\n",
    "    print('Accuracy score: ', accuracy_score(Ytest, pred))\n",
    "    print('F1 score: ', f1_score(Ytest, pred, average=avg_metric))\n",
    "    print('Average precision score: ', average_precision_score(Ytest, pred, average=avg_metric))\n",
    "    print('Average recall score: ', recall_score(Ytest, pred, average=avg_metric))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:  0.162\n",
      "F1 score:  0.5300136708231492\n",
      "Average precision score:  0.345828963534897\n",
      "Average recall score:  0.3998125\n"
     ]
    }
   ],
   "source": [
    "# Average with micro\n",
    "scores_averaging(Ytest, pred, \"micro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:  0.162\n",
      "F1 score:  0.1939167429826198\n",
      "Average precision score:  nan\n",
      "Average recall score:  0.1345445223904179\n"
     ]
    }
   ],
   "source": [
    "# Average with macro\n",
    "scores_averaging(Ytest, pred, \"macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:  0.162\n",
      "F1 score:  0.478011203813244\n",
      "Average precision score:  0.40694379720974916\n",
      "Average recall score:  0.3998125\n"
     ]
    }
   ],
   "source": [
    "# Average with weighted\n",
    "scores_averaging(Ytest, pred, \"weighted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Macro-average : This will calculate the average for each class independently and then take the average. \n",
    "\n",
    "Weighted - average : This will take into consideration of contribution of each label in the class and then returns the average considering the proportion for each label in the dataset.\n",
    "\n",
    "<b>Micro-average : This will take into consideration of contribution of all the classes to compute the average. Hence as we are seeing a class imbalance on the labels, this metric is favorable.<b>\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted -  ('17', 'male')\n",
      "Actual -  ('17', 'Cancer', 'Student', 'male')\n",
      "\n",
      "\n",
      "Predicted -  ('25', 'Virgo', 'female')\n",
      "Actual -  ('25', 'Virgo', 'female', 'indUnk')\n",
      "\n",
      "\n",
      "Predicted -  ('male',)\n",
      "Actual -  ('23', 'Marketing', 'Scorpio', 'male')\n",
      "\n",
      "\n",
      "Predicted -  ('male',)\n",
      "Actual -  ('16', 'Cancer', 'indUnk', 'male')\n",
      "\n",
      "\n",
      "Predicted -  ('female', 'indUnk')\n",
      "Actual -  ('23', 'Scorpio', 'female', 'indUnk')\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Function to print true label and predicted label for any five random values\n",
    "for i in range(5):\n",
    "    j = random.randint(0,len(Ytest))\n",
    "    print(\"Predicted - \", binarizer.inverse_transform(pred)[j])\n",
    "    print(\"Actual - \", binarizer.inverse_transform(Ytest)[j])  \n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
